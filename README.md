<!-- Centered title -->
<h1 align="center">âš¡ UK-DALE NILM â€” Linear / Logistic / MLP Baselines</h1>
<p align="center">
  <b>Building-1 Â· 1-min Aggregation Â· 14-Day Window</b><br/>
  Linear Regression Â· Logistic Regression Â· MLP Â· Multi-label Classification
</p>

---

## ğŸ“Œ TL;DR
We build robust baselines for **Non-Intrusive Load Monitoring (NILM)** on the UK-DALE dataset:
- **Single-appliance:** Kettle (regression + classification)
- **Multi-appliance:** Kettle, Microwave, Fridge-Freezer, Toaster (multi-label)
- Significant improvement from **logistic â†’ MLP**, and from **7-day â†’ 14-day** context

---

## ğŸ§  Model Performance Summary

### Single-Appliance (Kettle)
| Model | AUC | Precision | Recall | F1 | Notes |
|:--|--:|--:|--:|--:|--|
| Linear Regression | â€” | â€” | â€” | â€” | **MAE â‰ˆ 76 W**, stable watt-level baseline |
| Logistic (tuned) | **0.977** | 0.46 | 0.87 | 0.61 | Recall-optimized threshold |
| MLP (14d tuned) | **0.999** | **0.83** | **0.85** | **0.84** | âœ… Best single-appliance model |

### Multi-Appliance (14-Day MLP Tuned)
| Appliance | AUC | Precision | Recall | F1 | Comments |
|:--|--:|--:|--:|--:|--|
| **Kettle** | 0.995â€“0.998 | 0.47â€“0.83 | 0.85â€“0.98 | 0.61â€“0.84 | Distinct high spikes â†’ easy |
| **Microwave** | 0.986â€“0.996 | 0.71â€“0.97 | 0.29â€“0.39 | 0.44â€“0.50 | Sparse short events |
| **Fridge-Freezer** | 0.922â€“0.954 | **0.85â€“0.87** | **0.63â€“0.75** | **0.72â€“0.81** | Quasi-steady appliance |
| **Toaster** | 0.938â€“0.990 | 0.34â€“1.00 | 0.67â€“0.95 | 0.45â€“0.65 | Low-duration peaks |

> ğŸ“„ Full metrics in `multilabel_eval_summary.csv`  
> ğŸ¯ Thresholds stored in `multilabel_thresholds.json`

---

## ğŸ“ˆ Visual Results

### ğŸ§© Alignment (Ground Truth vs Mains)
<p align="center">
  <img src="plots/preview.png" width="780" alt="Mains vs Kettle preview"/>
  <br/>
  <sub>Mains vs Kettle: two-day slice used to verify alignment and sampling.</sub>
</p>

---

### âš™ï¸ Regression & Logistic Models
<table>
  <tr>
    <td align="center">
      <img src="plots/linreg_kettle_test_overlay.png" width="250" alt="Linear regression"/><br/>
      <sub>Linear regression: predicted wattage vs true usage.</sub>
    </td>
    <td align="center">
      <img src="plots/logreg_kettle_threshold_tuning.png" width="250" alt="Logistic tuning"/><br/>
      <sub>Logistic regression: precisionâ€“recall vs threshold.</sub>
    </td>
    <td align="center">
      <img src="plots/logreg_kettle_rolling_tuning.png" width="250" alt="Rolling logistic"/><br/>
      <sub>Rolling logistic: lagged features improve stability.</sub>
    </td>
  </tr>
</table>

---

### ğŸ¤– Neural Networks (MLP)
<table>
  <tr>
    <td align="center">
      <img src="plots/mlp_kettle_probs.png" width="250" alt="MLP kettle probabilities"/><br/>
      <sub>MLP probability trajectory (7â€“14d context).</sub>
    </td>
    <td align="center">
      <img src="plots/mlp_kettle_14d.png" width="250" alt="MLP 14d"/><br/>
      <sub>14-day context boosts recall and smooths predictions.</sub>
    </td>
    <td align="center">
      <img src="plots/mlp_kettle_14d_tuned.png" width="250" alt="MLP tuned"/><br/>
      <sub>Tuned threshold for recall â‰¥ 0.85.</sub>
    </td>
  </tr>
</table>

---

### ğŸ§® Multi-Label Overview
<p align="center">
  <img src="plots/multilabel_confusion.png" width="780" alt="Multilabel confusion matrix"/>
  <br/>
  <sub>Aggregated confusion across Kettle, Microwave, Fridge-Freezer, and Toaster.</sub>
</p>

---

## ğŸ”¬ Key Insights
- **Temporal context** (14d > 7d) significantly improves recall for short-duration spikes.  
- **Threshold tuning** by target recall (â‰¥ 0.85) balances precisionâ€“recall trade-offs.  
- **Fridge-Freezer** and **Toaster** benefit from nonlinear transformations (MLP).  
- **Multi-label setup** enhances rare appliance robustness.  
- **Rolling logistic** provides smoother prediction continuity.

---

## ğŸ›£ï¸ Next Steps
- ğŸ“ˆ Handle **class imbalance** via weighted BCE or SMOTE.  
- ğŸ§  Integrate **Bayesian optimization** for hyperparameter tuning.  
- ğŸ” Add **sequence models** (LSTM, Transformer) for long-range context.  
- ğŸ  Extend training to **Buildings 2â€“5** for cross-domain generalization.  
- ğŸŒ Build **Streamlit dashboard** for interactive NILM visualization.  

---

## âš™ï¸ Setup

```bash
conda create -n ukdale311 python=3.11 -y
conda activate ukdale311
pip install -r requirements.txt
pip install "git+https://github.com/nilmtk/nilmtk.git"

